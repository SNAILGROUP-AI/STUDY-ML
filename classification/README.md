# 지도학습이란
1. 모델이 학습할 설명변수의 조합과 그에 대응하는 반응변수 쌍을 데이터 셋으로 구성하여 사용하는 학습 방법
2. 사이킷런의 지도학습용 estimator은 fit(X, y)로 학습하고 predict(X)로 예측함
3. 분류분석
    - 반응변수가 범주형 변수(혹은 질적 변수)인 경우
    - 데이터를 나누는 작업으로서 발산작업
    - 어떠한 기준으로 분류할 것인가
4. 회귀분석
    - 반응변수가 수치형 변수(혹은 양적 변수)인 경우
    - 데이터의 추세를 요약하는 작업으로서 수렴작업
    - 다양하게 분포되어 있는 데이터의 추세를 가장 잘 설명하는 대표적인 문장이 무엇인가

---

# 분류분석(classification)
1. 데이터를 어떠한 기준에 따라 몇 가지 범주로 나누는 작업
    - 명확한 정답이 주어진 상태에서 먼저 학습한 뒤에 미지의 정답을 예측함
    - 대상의 정체를 규명함
    - 이항분류분석(binary classification) : 대상을 둘 중 하나로 분류하는 분석 방법
    - 다항분류분석(multi-category classificaiton) : 대상을 3개 이상의 범주 중 하나로 분류하는 분석 방법
2. 분류분석의 학습이란
    - 학습 데이터를 잘 분류할 수 있는 함수를 찾는 행위
    - 함수의 형태는 수식일 수도 있고, 규칙일 수도 있음
    - 이상적인 함수(분류기)는 학습에 사용되지 않은 데이터에 대해서도 잘 적용될 수 있는 함수
3. 분류 알고리즘의 예시
    - 결정트리
    - 서포트 벡터 머신
    - 최근접이웃
    - 로지스틱 회귀
    - 에이다부스트
    - 확률그레프모델
    - 랜덤포레스트
    - 다층퍼셉트론신경망
    - 딥러닝

---

# 결정 트리 알고리즘
1. 주어진 데이터에 내재되어 있는 규칙을 발견하여 tree 기반의 분류 규칙을 세우고 데이터를 분류하는 알고리즘
2. tree를 어떻게 분할할 것인가
    - 가지를 몇 번 뻗을 것인가
    - 한 범주당 데이터가 몇 개 남았을 때 멈출 것인가
3. 구조
    - root node : 최상위 node
    - decision node : 규칙
    - leaf node : 최종 범주
    - gini : 데이터 분포의 지니 계수
    - samples : 하나의 규칙에 해당하는 데이터 건수
    - value : 범주값 기반의 데이터 건수
4. 주의사항
    - node가 깊어질수록 예측 성능이 저하될 수 있음
    - 가급적 균일한 데이터 세트를 구성할 수 있도록 분할할 수 있게 해야 함
5. 균일도 측정 방법
    - 데이터 셋이 균일한 양상을 띠고 있다고 간주함
        - 최종적으로 검정색 바둑알로만 되어 있으면 균일도가 높다고 볼 수 있음
        - 최종적으로 검정색 바둑알에 흰색 바둑알이 조금 섞여 있으면 균일도가 중간 정도라고 볼 수 있음
        - 최종적으로 검정색 바둑알에 흰색 바둑알이 많이 섞여 있으면 균일도가 낮다고 볼 수 있음
    - decision node에서는 균일도가 높은 데이터 세트를 먼저 분류할 수 있도록 규칙을 구성함
6. 지니 계수 (불순도)
    - 균일도 측정 방법
    - 본래 경제학에서 불평등 지수를 나타낼 때 사용하는 계수로서, 0에 가까울수록 평등하고, 1에 가까울수록 불평등하다고 간주함
    - 데이터 세트를 분할하는데 가장 좋은 조건, 즉 지니계수가 높은 조건을 찾아서 자식 node에 반복적으로 분할한 뒤 데이터가 모두 특정 분류에 속하게 되면 분할 중지
    - 지니 계수를 낮추는 방향으로 가지치기를 진행함

---

# 최근접 이웃 알고리즘
1. 정의
    - 가장 고전적이고 직관적인 분류분석 알고리즘
    - 기하학적 거리에 기초하여 데이터를 분류함
    - 임의의 설명변수 조합이 나타내는 좌표평면 상의 한 점에 대하여,
    - 해당 점과 가장 가깝게 위치하는 점이 의미하는 설명변수 조합의 범주로 분류함
    - hyperparameter `n_neighbors` : 참조할 이웃의 수
    ![최근접이웃](https://miro.medium.com/max/405/0*QyWp7J6eSz0tayc0.png)

---

# 로지스틱 회귀 알고리즘


---

# 성능 평가 지표

1. 성능 평가
    - 성능은 반응변수가 주어져야 측정 가능하므로 성능 평가는 지도학습에서만 가능함
    - 모델링 목적 또는 반응변수의 유형에 따라 다른 평가지표 사용
        - 분류분석(범주형 변수) : 정확도, 정밀도, 재현율, F1-score 등
        - 회귀분석(연속형 변수) : mse, rmse, mae, mape 등
    - 성능은 오차(예측값과 실제값의 차이)를 기준으로 평가함
    - 오차를 0으로 만드는 것은 현실적으로 불가능하므로 오차를 허용할 범위를 결정해야 함

2. 목적
    - 과적합(overfitting) 방지 및 최적 모델 채택
    - 

모델링의 목적 또는 목표 변수의 유형에 따라 다른 평가지표를 사용한다.

Training과 Validation값이 거의 일치해야 좋은 모델이다.

만약 Training데이터로는 성능이 좋게 나왔는데, Validation 데이터를 사용했을 때 성능이 확연하게 떨어진다면 모델이 과적합된 상태이다.

3. 오차행렬(confusion matrix)
    ![](https://miro.medium.com/max/1400/1*4c3YSE9UrrmulLu0K66g1Q.png)
    - 오차행렬
        - 분류분석 결과 예측 범주와 실제 범주를 교차 표(cross table) 형태로 정리한 행렬
        - 이항분류에 대하여 예측 오류가 얼마인지와 더불어 어떠한 유형의 예측 오류가 발생하고 있는지 나타냄
    - True Positive : 예측값이 1이고, 실제값도 1인 경우
    - True Negative : 예측값이 0이고, 실제값도 0인 경우
    - False Positive : 예측값이 1이고, 실제값은 0인 경우로서 제1종 오류
    - False Nagative : 예측값이 0이고, 실제값은 1인 경우로서 제2종 오류

4. 정확도, 오류율, 정밀도, 재현율
    ![](https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg)

5. 정확도(Accuracy)
    - 정의
        - 전체 예측 개수 중 정확하게 예측한 개수
        - tp + tn / tp + tn + fp + fn 
    - 실제 데이터와 예측 데이터가 얼마나 동일한지를 평가 기준으로 하는 지표
    - scikit-learn `accuracy_score`
    - 범주 간 불균형한 데이터의 경우 적합하지 않음
        - 광고 노출 수와 클릭 수는 99:1
        - 무조건 클릭아님을 선택하면 99%의 정확도를 가지게 됨

6. 오류율
    - 정의
        - 전체 예측 개수 중 틀리게 예측한 개수
        - fp + fn / tp + tn + fp + fn

6. 정밀도
    - 정의
        - tp / tp + fp
        - 참으로 예측한 것들 중 정확하게 예측한 개수의 비중
    - 제1종 오류가 문제가 되는 경우 주요한 지표로서 사용됨
        - 실제 거짓인 데이터를 참으로 판단하면 큰 문제가 발생하는 경우

7. 재현율(혹은 민감도(sensitivity))
    - 정의
        - tp / tp + fn
        - 참인 것들 중 참으로 예측한 개수의 비중
    - 모델의 안정성을 평가하는 지표로서 사용됨
    - 제2종 오류가 문제가 되는 경우 주요한 지표로서 사용됨
        - 실제 참인 데이터를 거짓으로 판단하면 큰 문제가 발생하는 경우

8. f1-score(f-measure)
    - 정의
        - 정밀도와 재현율의 조화 평균
        - 정밀도와 재현율 중 어느 한쪽으로 치우치지 않을수록 높은 값을 가짐
    - 정밀도와 재현율은 트레이드 오프 관계
        - 정밀도와 재현율 모두 tp를 높이는데 초점을 맞춤
        - 단, 정밀도는 fp를 낮추는 것에, 재현율은 fn을 낮추는 것에 초점을 맞춤
        - 어느 한쪽의 수치를 강제로 높이면 다른 한쪽의 수치를 낮추기 쉬워짐
            - 어떤 자료가 참일 확률이 0.9라면 참일 가능성이 매우 높음
            - 어떤 자료가 참일 확률이 0.1이라면 거짓일 가능성이 매우 높음
            - 그렇다면 어떤 자료가 참일 확률이 0.6일 경우 어떻게 분류해야 하는가
            - 임계값(threshold)을 기준으로 분류함








정확도, 정밀도, 재현율, F1-Score는 모두 0~1 사이의 값을 가지며, 1에 가까워질수록 성능이 좋다는 것을 의미한다.

ROC 곡선과 AUC
ROC 곡선은 FPR(False Positive Rate)이 변할 때 TPR(True Positive Rate)이 어떻게 변하는지 나타내는 곡선

TPR(True Positive Rate): TP / (FN + TP), 재현율
TNR(True Negative Rate): TN / (FP + TN)
FPR(False Positive Rate): FP / (FP + TN), 1 - TNR
참 양성비율(TPR)에 대한 거짓 양성 비율(FPR)

AUC(Area Under Curve) 값은 ROC 곡선 밑에 면적을 구한 값 (1이 가까울수록 좋은 값)

AUC의 장점

AUC는 척도 불변(Scale-Invariant): 절대값이 아닌, 예측이 얼마나 잘 평가되었는지는 측정
AUC는 분류 임계값 불변(Classification-Threshold-Invariant): 어떤 분류 임계값이 선택되었는지와 무관하게 모델의 에측 품질을 측정