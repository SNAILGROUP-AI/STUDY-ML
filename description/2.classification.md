## 분류분석이란 무엇인가

- **정의 : 데이터를 나누는 발산 작업**
    - 대상의 정체를 규명하는 작업
    - 데이터를 일정한 기준에 따라 몇 가지 범주로 나누는 작업
    - 반응변수가 범주형 변수인 경우

- **학습 양상**
    - 분류분석 시 학습은 데이터를 잘 분류할 수 있는 함수를 찾는 행위임
    - 함수의 형태는 수식이 될 수도 있고, 규칙이 될 수도 있음
    - 이상적인 분류기는 새로운 데이터를 잘 규명할 수 있는 분류기

- **이슈 : 어떠한 기준으로 분류할 것인가** 

- **구분**
    - **이항분류분석(binary classification)** : 대상을 둘 중 하나로 분류하는 분석 방법
    - **다항분류분석(multi-category classificaiton)** : 대상을 3개 이상의 범주 중 하나로 분류하는 분석 방법

---

## 주요 알고리즘

<details><summary><h3>결정 트리</h3></summary>

- **정의**
    - 정의 : 데이터에 내재된 규칙을 발견하여 수형도 기반의 분류 규칙을 세우고 데이터를 분류하는 알고리즘
    
    - 주요 이슈 : 트리를 어떻게 분할할 것인가
        - 가지를 몇 번 뻗을 것인가
        - 한 범주당 데이터가 몇 개 남았을 때 가지치기를 멈출 것인가
    
    - 주의 사항
        - node가 깊어질수록 성능이 저하될 수 있음
        - 범주마다 균일한 데이터 세트를 구성할 수 있도록 하이퍼파라미터를 설정해야 함

- **구조**
    다운로드.png
    - root node : 최상위 노드
    - decision node : 규칙 노드
    - leaf node : 최종 범주
    - gini : 데이터 분포의 균일도
    - samles : 임의의 규칙에 대하여 해당 규칙을 만족하는 데이터 건수
    - value : 각 범주의 데이터 건수

- **지니계수**
    - **균일도**
        - 정의 : leaf node에 각 범주에 해당하는 데이터만 포함되어 있는가
            - `color`을 기준으로 바둑알을 구분한다고 가정하자
            - 범주로는 `black` , `white` 가 존재함
            - 범주 `black`에 검정색 바둑알만 포함되어 있다면 균일도가 높다고 해석함
            - 범주 `black`에 흰색 바둑알이 많이 섞여 있을수록 균일도가 낮다고 해석함
        
        - decision node에서는 균일도가 높은 데이터 셋을 먼저 분류할 수 있도록 규칙을 구성함

    - **지니계수**
        - 정의 : 균일도를 측정하는 방법 혹은 불순도를 측정하는 방법
            - 지니계수가 높을수록 균일도가 낮고, 불순도가 높다고 해석함
            - 본래 경제학에서 불평등 지수를 나타낼 때 사용하는 지수였음
            - 0에 가까울수록 평등하고, 1에 가까울수록 불평등하다고 해석했음
        
        - 결정 트리는 지니계수를 낮추는 방향으로 가지치기를 진행함
            - 데이터 셋을 분할하는 데 가장 좋은 조건인 지니계수가 낮은 조건을 찾음
            - 해당 조건에 기초하여 데이터 셋을 하위 노드에 반복적으로 분할함
            - 모든 데이터가 특정 범주에 속하게 되면 분할을 중지함

</details>

<details><summary><h3>최근접 이웃</h3></summary>

</details>

<details><summary><h3>로지스틱 회귀</h3></summary>

</details>

---

## 성능 평가 지표

---

## Practice

- [**실습 코드**]()
- [**데이터 명세서**]()







# 최근접 이웃 알고리즘
1. 정의
    - 가장 고전적이고 직관적인 분류분석 알고리즘
    - 기하학적 거리에 기초하여 데이터를 분류함
    - 임의의 설명변수 조합이 나타내는 좌표평면 상의 한 점에 대하여,
    - 해당 점과 가장 가깝게 위치하는 점이 의미하는 설명변수 조합의 범주로 분류함
    - hyperparameter `n_neighbors` : 참조할 이웃의 수
    ![최근접이웃](https://miro.medium.com/max/405/0*QyWp7J6eSz0tayc0.png)

---

# 로지스틱 회귀 알고리즘


---

# 성능 평가 지표

1. 성능 평가
    - 성능은 반응변수가 주어져야 측정 가능하므로 성능 평가는 지도학습에서만 가능함
    - 모델링 목적 또는 반응변수의 유형에 따라 다른 평가지표 사용
        - 분류분석(범주형 변수) : 정확도, 정밀도, 재현율, F1-score 등
        - 회귀분석(연속형 변수) : mse, rmse, mae, mape 등
    - 성능은 오차(예측값과 실제값의 차이)를 기준으로 평가함
    - 오차를 0으로 만드는 것은 현실적으로 불가능하므로 오차를 허용할 범위를 결정해야 함

2. 목적
    - 과적합(overfitting) 방지 및 최적 모델 채택
    - 

모델링의 목적 또는 목표 변수의 유형에 따라 다른 평가지표를 사용한다.

Training과 Validation값이 거의 일치해야 좋은 모델이다.

만약 Training데이터로는 성능이 좋게 나왔는데, Validation 데이터를 사용했을 때 성능이 확연하게 떨어진다면 모델이 과적합된 상태이다.

3. 오차행렬(confusion matrix)
    ![](https://miro.medium.com/max/1400/1*4c3YSE9UrrmulLu0K66g1Q.png)
    - 오차행렬
        - 분류분석 결과 예측 범주와 실제 범주를 교차 표(cross table) 형태로 정리한 행렬
        - 이항분류에 대하여 예측 오류가 얼마인지와 더불어 어떠한 유형의 예측 오류가 발생하고 있는지 나타냄
    - True Positive : 예측값이 1이고, 실제값도 1인 경우
    - True Negative : 예측값이 0이고, 실제값도 0인 경우
    - False Positive : 예측값이 1이고, 실제값은 0인 경우로서 제1종 오류
    - False Nagative : 예측값이 0이고, 실제값은 1인 경우로서 제2종 오류

4. 정확도, 오류율, 정밀도, 재현율
    ![](https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg)

5. 정확도(Accuracy)
    - 정의
        - 전체 예측 개수 중 정확하게 예측한 개수
        - tp + tn / tp + tn + fp + fn 
    - 실제 데이터와 예측 데이터가 얼마나 동일한지를 평가 기준으로 하는 지표
    - scikit-learn `accuracy_score`
    - 범주 간 불균형한 데이터의 경우 적합하지 않음
        - 광고 노출 수와 클릭 수는 99:1
        - 무조건 클릭아님을 선택하면 99%의 정확도를 가지게 됨

6. 오류율
    - 정의
        - 전체 예측 개수 중 틀리게 예측한 개수
        - fp + fn / tp + tn + fp + fn

6. 정밀도
    - 정의
        - tp / tp + fp
        - 참으로 예측한 것들 중 정확하게 예측한 개수의 비중
    - 제1종 오류가 문제가 되는 경우 주요한 지표로서 사용됨
        - 실제 거짓인 데이터를 참으로 판단하면 큰 문제가 발생하는 경우

7. 재현율(혹은 민감도(sensitivity))
    - 정의
        - tp / tp + fn
        - 참인 것들 중 참으로 예측한 개수의 비중
    - 모델의 안정성을 평가하는 지표로서 사용됨
    - 제2종 오류가 문제가 되는 경우 주요한 지표로서 사용됨
        - 실제 참인 데이터를 거짓으로 판단하면 큰 문제가 발생하는 경우

8. f1-score(f-measure)
    - 정의
        - 정밀도와 재현율의 조화 평균
        - 정밀도와 재현율 중 어느 한쪽으로 치우치지 않을수록 높은 값을 가짐
    - 정밀도와 재현율은 트레이드 오프 관계
        - 정밀도와 재현율 모두 tp를 높이는데 초점을 맞춤
        - 단, 정밀도는 fp를 낮추는 것에, 재현율은 fn을 낮추는 것에 초점을 맞춤
        - 어느 한쪽의 수치를 강제로 높이면 다른 한쪽의 수치를 낮추기 쉬워짐
            - 어떤 자료가 참일 확률이 0.9라면 참일 가능성이 매우 높음
            - 어떤 자료가 참일 확률이 0.1이라면 거짓일 가능성이 매우 높음
            - 그렇다면 어떤 자료가 참일 확률이 0.6일 경우 어떻게 분류해야 하는가
            - 임계값(threshold)을 기준으로 분류함








정확도, 정밀도, 재현율, F1-Score는 모두 0~1 사이의 값을 가지며, 1에 가까워질수록 성능이 좋다는 것을 의미한다.

ROC 곡선과 AUC
ROC 곡선은 FPR(False Positive Rate)이 변할 때 TPR(True Positive Rate)이 어떻게 변하는지 나타내는 곡선

TPR(True Positive Rate): TP / (FN + TP), 재현율
TNR(True Negative Rate): TN / (FP + TN)
FPR(False Positive Rate): FP / (FP + TN), 1 - TNR
참 양성비율(TPR)에 대한 거짓 양성 비율(FPR)

AUC(Area Under Curve) 값은 ROC 곡선 밑에 면적을 구한 값 (1이 가까울수록 좋은 값)

AUC의 장점

AUC는 척도 불변(Scale-Invariant): 절대값이 아닌, 예측이 얼마나 잘 평가되었는지는 측정
AUC는 분류 임계값 불변(Classification-Threshold-Invariant): 어떤 분류 임계값이 선택되었는지와 무관하게 모델의 에측 품질을 측정