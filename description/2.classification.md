## 🤓 분류분석이란 무엇인가

- **정의 : 데이터를 나누는 발산 작업**
    - 대상의 정체를 규명하는 작업
    - 데이터를 일정한 기준에 따라 몇 가지 범주로 나누는 작업
    - 반응변수가 범주형 변수인 경우

- **학습 양상**
    - 분류분석에서 학습은 주어진 데이터를 잘 분류할 수 있는 함수를 찾는 행위임
    - 함수의 형태는 수식이 될 수도 있고, 규칙이 될 수도 있음
    - 이상적인 분류기는 새로운 데이터의 정체를 잘 규명할 수 있음

- **이슈 : 어떠한 기준으로 분류할 것인가** 

- **구분**
    - **이항분류분석(binary classification)** : 대상을 둘 중 하나로 분류하는 분석 방법
    - **다항분류분석(multi-category classificaiton)** : 대상을 3개 이상의 범주 중 하나로 분류하는 분석 방법

---

## 🌳 결정 트리(Decision Tree)

<details><summary><h3>결정 트리란 무엇인가</h3></summary>

- **정의 : 데이터에 내재된 규칙을 발견하여 수형도 기반의 분류 규칙을 세우고 데이터를 분류하는 알고리즘**
    
- **주요 이슈 : 트리를 어떻게 분할할 것인가**
    - 가지를 몇 번 뻗을 것인가
    - 한 범주당 데이터가 몇 개 남았을 때 가지치기를 멈출 것인가
    
- **주의 사항**
    - node가 깊어질수록 성능이 저하될 수 있음
    - 범주마다 균일한 데이터 세트를 구성할 수 있도록 하이퍼파라미터를 설정해야 함

- **균일도**
    - 정의 : leaf node에 각 범주에 해당하는 데이터만 포함되어 있는가
    
    - 예시
        - `color`을 기준으로 바둑알을 구분한다고 가정하자
        - 범주로는 `black` , `white` 가 존재함
        - 범주 `black`에 검정색 바둑알만 포함되어 있다면 균일도가 높다고 해석함
        - 범주 `black`에 흰색 바둑알이 많이 섞여 있을수록 균일도가 낮다고 해석함
    
    - decision node에서는 균일도가 높은 데이터 셋을 먼저 분류할 수 있도록 규칙을 구성함

- **지니계수**
    - 정의 : 균일도를 측정하는 방법 혹은 불순도를 측정하는 방법
        - 지니계수가 높을수록 균일도가 낮고, 불순도가 높다고 해석함
        - 본래 경제학에서 불평등 지수를 나타낼 때 사용하는 지수였음
        - 0에 가까울수록 평등하고, 1에 가까울수록 불평등하다고 해석했음
    
    - 결정 트리는 지니계수를 낮추는 방향으로 가지치기를 진행함
        - 데이터 셋을 분할하는 데 가장 좋은 조건인 지니계수가 낮은 조건을 찾음
        - 해당 조건에 기초하여 데이터 셋을 하위 노드에 반복적으로 분할함
        - 모든 데이터가 특정 범주에 속하게 되면 분할을 중지함

<details><summary><h3>결정 트리의 구조</h3></summary>

![아이리스 결정트리 예시](https://user-images.githubusercontent.com/116495744/221340236-6c4043c6-6b30-4af2-9e7f-cfe79b00371a.png)

- **root node** : 최상위 노드

- **decision node** : 규칙 노드

- **leaf node** : 최종 범주

- **gini** : 데이터 분포의 균일도

- **samles** : 임의의 규칙에 대하여 해당 규칙을 만족하는 데이터 건수

- **value** : 각 범주의 데이터 건수

</details>

<details><summary><h3>SK-Learn의 결정 트리 알고리즘</h3></summary>

- **사용 방법**

</details>

---

## 👫 최근접 이웃(k-Nearest Neighbors; k-NN)

<details><summary><h3>최근접 이웃이란 무엇인가</h3></summary>

- **정의 : 기하학적 거리를 규칙으로 하여 데이터를 분류하는 알고리즘**
    - 임의의 설명변수 조합이 나타내는 좌표평면 상의 한 점에 대하여,
    - 해당 점과 가장 가깝게 위치하는 점이 의미하는 설명변수 조합의 범주로 분류함

- **주요 이슈 : 참조할 이웃의 수를 얼마로 설정할 것인가**

    ![최근접이웃](https://miro.medium.com/max/405/0*QyWp7J6eSz0tayc0.png)

</details>

<details><summary><h3>SK-Learn의 최근접 이웃 알고리즘</h3></summary>

- **사용 방법**

</details>

---

## 👥 로지스틱 회귀(Logistic Regression)

<details><summary><h3>로지스틱 회귀란 무엇인가</h3></summary>

</details>

<details><summary><h3>SK-Learn의 로지스틱 회귀 알고리즘</h3></summary>

- **사용 방법**

</details>

---

## 📝 Practice

- [**실습 코드**]()

- [**데이터 명세서**]()