## 🤓 회귀분석이란 무엇인가

4. 회귀분석
    - 반응변수가 수치형 변수(혹은 양적 변수)인 경우
    - 데이터의 추세를 요약하는 작업으로서 수렴작업
    - 다양하게 분포되어 있는 데이터의 추세를 가장 잘 설명하는 대표적인 문장이 무엇인가

---

## 📈 선형 회귀(Linear Regression)

<details><summary><h3>선형 회귀란 무엇인가</h3></summary>

- **정의 : 최소제곱법을 통해 회귀식을 도출하는 알고리즘**

- **최소제곱법(Ordinary Least Squares; OLS)** : 잔차 제곱의 합을 최소화하는 회귀식을 도출하는 방법

- **최소제곱법의 수학적 이해**
    - 임의의 반응변수 $Y$ 가 설명변수 $X$ 와 선형 관계에 있다고 가정하자

    - 샘플 $i$ 에 대하여 반응변수와 설명변수의 회귀식은 다음과 같음
        
        ### $$Y_i=b_1+b_2X_i+e_i$$

        - $b_1$ : 상수항; 설명변수의 영향력이 모두 제거되었을 때 반응변수의 상태
        - $b_2$ : 기울기; 반응변수 $Y_i$ 에 대한 설명변수 $X_i$ 의 영향력
        - $e_i$ : 잔차항; 반응변수의 초기 상태와 설명변수의 영향력의 조합만으로는 설명될 수 없는 항목의 모음

    - 잔차항은 구체적으로 다음을 의미함

        ![image](https://user-images.githubusercontent.com/116495744/221339174-de431950-85c5-4156-afbc-0d3ba0b9c8e4.png)

    - 잔차 제곱의 합을 최소화한다는 것은 다음을 의미함
        
        ### $\min\displaystyle\sum_{i=1}^ne_i^2=\min\sum_{i=1}^n(Y_i-b_1-b_2X_i)^2$

</details>

<details><summary><h3>SK-Learn의 선형 회귀 알고리즘</h3></summary>
    
- **사용 방법**

    ```
    from sklearn.linear_model import LinearRegression
    from sklearn.metrics import r2_score

    # 선형 회귀 알고리즘 인스턴스 생성
    li_reg = LinearRegression()

    # 훈련용 데이터 세트를 통해 인스턴스를 훈련시켜서 모델 설계
    li_reg.fit(X_train, y_train)

    # 평가용 데이터 세트를 통해 예측
    y_predict = li_reg.predict(X_test)
    
    # 대표적인 성능 평가 지표인 결정계수를 통해 성능 평가
    score = r2_score(y_test, y_predict)
    print(score)
    ```

- **주요 하이퍼파라미터**

- **다음의 속성을 통해 훈련된 모델의 정보를 확인할 수 있음**

    - `n_features_in_` : 설명변수의 수
    - `feature_nmaes_in_` : 설명변수명
    - `coef_` : 각 설명변수의 가중치 혹은 기울기
    - `intercept_` : 편향성

</details>

---

## 📉 확률적 경사 하강 회귀(Stochastic Gradient Descent Regression; SGD)

<details><summary><h3>확률적 경사 하강 회귀</h3></summary>

</details>

<details><summary><h3>SK-Learn의 확률적 경사 하강 회귀 알고리즘</h3></summary>

</details>

---

## 📝 Practice

- [**실습 코드**]()

- [**데이터 명세서**]()