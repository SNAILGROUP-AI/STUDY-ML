## π¤“ νκ·€λ¶„μ„μ΄λ€ λ¬΄μ—‡μΈκ°€

4. νκ·€λ¶„μ„
    - λ°μ‘λ³€μκ°€ μμΉν• λ³€μ(νΉμ€ μ–‘μ  λ³€μ)μΈ κ²½μ°
    - λ°μ΄ν„°μ μ¶”μ„Έλ¥Ό μ”μ•½ν•λ” μ‘μ—…μΌλ΅μ„ μλ ΄μ‘μ—…
    - λ‹¤μ–‘ν•κ² λ¶„ν¬λμ–΄ μλ” λ°μ΄ν„°μ μ¶”μ„Έλ¥Ό κ°€μ¥ μ μ„¤λ…ν•λ” λ€ν‘μ μΈ λ¬Έμ¥μ΄ λ¬΄μ—‡μΈκ°€

---

## π“ μ„ ν• νκ·€(Linear Regression)

<details><summary><h3>μ„ ν• νκ·€λ€ λ¬΄μ—‡μΈκ°€</h3></summary>

- **μ •μ : μµμ†μ κ³±λ²•μ„ ν†µν•΄ νκ·€μ‹μ„ λ„μ¶ν•λ” μ•κ³ λ¦¬μ¦**

- **μµμ†μ κ³±λ²•(Ordinary Least Squares; OLS)** : μ”μ°¨ μ κ³±μ ν•©μ„ μµμ†ν™”ν•λ” νκ·€μ‹μ„ λ„μ¶ν•λ” λ°©λ²•

- **μµμ†μ κ³±λ²•μ μν•™μ  μ΄ν•΄**
    - μ„μμ λ°μ‘λ³€μ $Y$ κ°€ μ„¤λ…λ³€μ $X$ μ™€ μ„ ν• κ΄€κ³„μ— μλ‹¤κ³  κ°€μ •ν•μ

    - μƒν” $i$ μ— λ€ν•μ—¬ λ°μ‘λ³€μμ™€ μ„¤λ…λ³€μμ νκ·€μ‹μ€ λ‹¤μκ³Ό κ°™μ
        
        ### $$Y_i=b_1+b_2X_i+e_i$$

        - $b_1$ : μƒμν•­; μ„¤λ…λ³€μμ μν–¥λ ¥μ΄ λ¨λ‘ μ κ±°λμ—μ„ λ• λ°μ‘λ³€μμ μƒνƒ
        - $b_2$ : κ°€μ¤‘μΉ; λ°μ‘λ³€μ $Y_i$ μ— λ€ν• μ„¤λ…λ³€μ $X_i$ μ μν–¥λ ¥
        - $e_i$ : μ”μ°¨ν•­; λ°μ‘λ³€μμ μ΄κΈ° μƒνƒμ™€ μ„¤λ…λ³€μμ μν–¥λ ¥μ μ΅°ν•©λ§μΌλ΅λ” μ„¤λ…λ  μ μ—†λ” ν•­λ©μ λ¨μ

    - μ”μ°¨ν•­ νΉμ€ μ¤μ°¨λ” κµ¬μ²΄μ μΌλ΅ λ‹¤μμ„ μλ―Έν•¨

        ![image](https://user-images.githubusercontent.com/116495744/221339174-de431950-85c5-4156-afbc-0d3ba0b9c8e4.png)

    - μ”μ°¨ μ κ³±μ ν•©μ„ μµμ†ν™”ν•λ‹¤λ” κ²ƒμ€ λ‹¤μμ„ μλ―Έν•¨
        
        ### $$\min\displaystyle\sum_{i=1}^ne_i^2=\min\sum_{i=1}^n(Y_i-b_1-b_2X_i)^2$$

</details>

<details><summary><h3>SK-Learnμ μ„ ν• νκ·€ μ•κ³ λ¦¬μ¦</h3></summary>
    
- **μ‚¬μ© λ°©λ²•**

    ```
    from sklearn.linear_model import LinearRegression
    from sklearn.metrics import r2_score

    # μ„ ν• νκ·€ μ•κ³ λ¦¬μ¦ μΈμ¤ν„΄μ¤ μƒμ„±
    li_reg = LinearRegression()

    # ν›λ ¨μ© λ°μ΄ν„° μ„ΈνΈλ¥Ό ν†µν•΄ μΈμ¤ν„΄μ¤λ¥Ό ν›λ ¨μ‹μΌμ„ λ¨λΈ μ„¤κ³„
    li_reg.fit(X_train, y_train)

    # ν‰κ°€μ© λ°μ΄ν„° μ„ΈνΈλ¥Ό ν†µν•΄ μμΈ΅
    y_predict = li_reg.predict(X_test)
    
    # λ€ν‘μ μΈ μ„±λ¥ ν‰κ°€ μ§€ν‘μΈ κ²°μ •κ³„μλ¥Ό ν†µν•΄ μ„±λ¥ ν‰κ°€
    score = r2_score(y_test, y_predict)
    print(score)
    ```

- **μ£Όμ” ν•μ΄νΌνλΌλ―Έν„°**

- **λ‹¤μμ μ†μ„±μ„ ν†µν•΄ ν›λ ¨λ λ¨λΈμ μ •λ³΄λ¥Ό ν™•μΈν•  μ μμ**

    - `n_features_in_` : μ„¤λ…λ³€μμ μ
    - `feature_nmaes_in_` : μ„¤λ…λ³€μλ…
    - `coef_` : κ° μ„¤λ…λ³€μμ κ°€μ¤‘μΉ νΉμ€ κΈ°μΈκΈ°
    - `intercept_` : νΈν–¥μ„±

</details>

---

## π“‰ ν™•λ¥ μ  κ²½μ‚¬ ν•κ°• νκ·€(Stochastic Gradient Descent Regression; SGD)

<details><summary><h3>ν™•λ¥ μ  κ²½μ‚¬ ν•κ°• νκ·€λ€ λ¬΄μ—‡μΈκ°€</h3></summary>

- **μ •μ : κ²½μ‚¬ν•κ°•λ²•μ„ ν†µν•΄ νκ·€μ‹μ„ λ„μ¶ν•λ” μ•κ³ λ¦¬μ¦**

- **ν™•λ¥ μ  κ²½μ‚¬ν•κ°•λ²•(Stochastic Gradient Descent; SGD)** : μµμ ν™”λ μ†μ‹¤ν•¨μμ— κ·Όκ±°ν•μ—¬ νκ·€μ‹μ„ λ„μ¶ν•λ” λ°©λ²•
    - **μ†μ‹¤(Loss)** : μ–΄λ– ν• λ°©λ²•μ— λ”°λΌ μ”μ°¨λ¥Ό κ³„μ‚°ν• κ°’
    - **μ†μ‹¤ν•¨μ(Loss Function)** : μ†μ‹¤μ„ λ°μ‘λ³€μ, κ°€μ¤‘μΉμ μ΅°ν•©μ„ μ„¤λ…λ³€μλ΅ κ°€μ§€λ” ν•¨μ
    - **μµμ ν™”(Optimizing)** : μ†μ‹¤μ„ μµμ†ν™”ν•λ” κ°€μ¤‘μΉ μ΅°ν•©μ„ μ°Ύλ” μΌ

- **ν™•λ¥ μ  κ²½μ‚¬ν•κ°•λ²•μ μν•™μ  μ΄ν•΄**
    - μ„μμ λ°μ‘λ³€μ $Y$ κ°€ μ„¤λ…λ³€μ $X$ μ™€ μ„ ν• κ΄€κ³„μ— μλ‹¤κ³  κ°€μ •ν•μ

    - μƒν” $i$ μ— λ€ν•μ—¬ λ°μ‘λ³€μμ™€ μ„¤λ…λ³€μμ νκ·€μ‹μ€ λ‹¤μκ³Ό κ°™μ
        
        ### $$Y_i=b_1+b_2X_i+e_i$$

        - $b_1$ : μƒμν•­; μ„¤λ…λ³€μμ μν–¥λ ¥μ΄ λ¨λ‘ μ κ±°λμ—μ„ λ• λ°μ‘λ³€μμ μƒνƒ
        - $b_2$ : κ°€μ¤‘μΉ; λ°μ‘λ³€μ $Y_i$ μ— λ€ν• μ„¤λ…λ³€μ $X_i$ μ μν–¥λ ¥
        - $e_i$ : μ”μ°¨ν•­; λ°μ‘λ³€μμ μ΄κΈ° μƒνƒμ™€ μ„¤λ…λ³€μμ μν–¥λ ¥μ μ΅°ν•©λ§μΌλ΅λ” μ„¤λ…λ  μ μ—†λ” ν•­λ©μ λ¨μ

    - μ”μ°¨ν•­ νΉμ€ μ¤μ°¨λ” κµ¬μ²΄μ μΌλ΅ λ‹¤μμ„ μλ―Έν•¨

        ![image](https://user-images.githubusercontent.com/116495744/221339174-de431950-85c5-4156-afbc-0d3ba0b9c8e4.png)

    - ν‰κ· μ κ³±μ¤μ°¨(MSE)μ— κΈ°μ΄ν• μ†μ‹¤ν•¨μλ” λ‹¤μμΌλ΅ μ •μλ¨

        ### $$LOSS_{MSE}=\frac{1}{N}\displaystyle\sum_{i=1}^n (\hat{Y_i}-Y_i)^2$$

    - μ™ κ²½μ‚¬λ¥Ό ν•κ°•ν•λ” λ°©λ²•μ΄λΌκ³  λ¶€λ¥΄λ”κ°€?
        - μ†μ‹¤ν•¨μμ λ°μ‘λ³€μμΈ μ†μ‹¤μ„ μµμ†ν™”ν•λ” μΌκ³„μ΅°κ±΄μ€ κ·Έ λ„ν•¨μμ λ°μ‘λ³€μκ°€ 0μ„ λ§μ΅±ν•λ” κ²ƒμ„
        - λ„ν•¨μμ λ°μ‘λ³€μλ” μ›ν•¨μμ κ²½μ‚¬(Gradient)λ¥Ό λ‚νƒ€λƒ„
        - λ”°λΌμ„ ν™•λ¥ μ  κ²½μ‚¬ν•κ°•λ²•μ€ μ›ν•¨μμ κ²½μ‚¬κ°€ μν‰μ΄ λλ” μ§€μ μ„ μ°Ύλ” μΌμ΄λΌκ³  λ³Ό μ μμ

- **μ£Όμ” μ΄μ : ν•™μµλ¥ (Learning Rate)**
    - ν™•λ¥ μ  κ²½μ‚¬ ν•κ°• νκ·€ μ•κ³ λ¦¬μ¦μ€ λ‹¤μμ μ μ°¨λ¥Ό ν†µν•΄ κ²½μ‚¬κ°€ 0μ— κ·Όμ‚¬ν• μ§€μ μ„ μ°Ύμ
    - μ¦‰, μ„μλ΅ μ„ νƒλ μ†μ‹¤ν•¨μ κ·Έλν”„μ ν• μ μ—μ„ μ‹μ‘ν•μ—¬ ν• STEPμ”© μ›€μ§μ΄λ©΄μ„ κ²½μ‚¬λ¥Ό ν™•μΈν•¨
    - **ν•™μµλ¥ (Learning Rate)** : STEPμ λ‹¨μ„ νΉμ€ λ³΄ν­
    - ν•™μµλ¥ μ€ μ •ν™•λ„μ— λΉ„λ΅€ν•κ³ , μ²λ¦¬ μ†λ„μ— λ°λΉ„λ΅€ν•¨

</details>

<details><summary><h3>SK-Learnμ ν™•λ¥ μ  κ²½μ‚¬ ν•κ°• νκ·€ μ•κ³ λ¦¬μ¦</h3></summary>

- **μ‚¬μ© λ°©λ²•**

    ```
    from sklearn.linear_model import SGDRegressor
    from sklearn.metrics import r2_score

    # ν™•λ¥ μ  κ²½μ‚¬ ν•κ°• νκ·€ μ•κ³ λ¦¬μ¦ μΈμ¤ν„΄μ¤ μƒμ„±
    sgd_reg = SGDRegressor()

    # ν›λ ¨μ© λ°μ΄ν„° μ„ΈνΈλ¥Ό ν†µν•΄ μΈμ¤ν„΄μ¤λ¥Ό ν›λ ¨μ‹μΌμ„ λ¨λΈ μ„¤κ³„
    sgd_reg.fit(X_train, y_train)

    # ν‰κ°€μ© λ°μ΄ν„° μ„ΈνΈλ¥Ό ν†µν•΄ μμΈ΅
    y_predict = sgd_reg.predict(X_test)
    
    # λ€ν‘μ μΈ μ„±λ¥ ν‰κ°€ μ§€ν‘μΈ κ²°μ •κ³„μλ¥Ό ν†µν•΄ μ„±λ¥ ν‰κ°€
    score = r2_score(y_test, y_predict)
    print(score)
    ```

- **μ£Όμ” ν•μ΄νΌνλΌλ―Έν„°**

    - `learning_rate = 0.1` : ν•™μµλ¥ 

- **λ‹¤μμ μ†μ„±μ„ ν†µν•΄ ν›λ ¨λ λ¨λΈμ μ •λ³΄λ¥Ό ν™•μΈν•  μ μμ**

    - `n_features_in_` : λ…λ¦½λ³€μμ μ
    - `feature_nmaes_in_` : λ…λ¦½λ³€μλ…
    - `coef_` : κ° λ…λ¦½λ³€μμ κ°€μ¤‘μΉ
    - `intercept_` : νΈν–¥μ„±

</details>

---

## π“ Practice

- [**μ‹¤μµ μ½”λ“**]()

- [**λ°μ΄ν„° λ…μ„Έμ„**]()