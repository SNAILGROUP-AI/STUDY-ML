## π¤“ νκ·€λ¶„μ„μ΄λ€ λ¬΄μ—‡μΈκ°€

- **μ •μ : λ°μ΄ν„°λ¥Ό μ”μ•½ν•λ” μλ ΄ μ‘μ—…**
    - λ°μ΄ν„°μ μ¶”μ„Έλ¥Ό μ„¤λ…ν•λ” ν• λ¬Έμ¥μ„ μ°Ύλ” μ‘μ—…
    - λ°μ‘λ³€μκ°€ μμΉν• λ³€μμΈ κ²½μ°

- **ν•™μµ μ–‘μƒ**
    - **ν•™μµ** : μµμ  νκ·€κ³„μ μ΅°ν•©μ„ μ°Ύλ” ν–‰μ„
    - **μµμ  νκ·€κ³„μ** : μ”μ°¨ν•­μ ν¬κΈ°λ¥Ό μµμ†ν™”ν•λ” νκ·€κ³„μ
    - **μ”μ°¨ν•­** : μ‹¤μ κ°’κ³Ό μμΈ΅κ°’μ μ°¨μ΄
    - **νκ·€κ³„μ** : κ°€μ¤‘μΉ(w)μ™€ νΈν–¥μ„±(b)

- **κµ¬λ¶„**
    - **λ‹¨μνκ·€λ¶„μ„(Simple egression Analysis)** : λ°μ‘λ³€μμ— λ€ν• μ„¤λ…λ³€μκ°€ ν•λ‚μΈ κ²½μ°
    - **λ‹¤μ¤‘νκ·€λ¶„μ„(Multiple Regression Analysis)** : λ°μ‘λ³€μμ— λ€ν• μ„¤λ…λ³€μκ°€ λ‘ κ°€μ§€ μ΄μƒμΈ κ²½μ°

- **νκ·€λ¶„μ„μ μν•™μ  μ΄ν•΄**
    - μμΉν• λ°μ‘λ³€μ $Y$ κ°€ μ„¤λ…λ³€μ $X$ μ™€ μ„ ν• κ΄€κ³„μ— μλ‹¤κ³  κ°€μ •ν•μ

    - μƒν” $i$ μ— λ€ν•μ—¬ λ°μ‘λ³€μμ™€ μ„¤λ…λ³€μμ νκ·€μ‹μ€ λ‹¤μκ³Ό κ°™μ
        
        ### $$Y_i=b+wX_i+e_i$$

        - $b$ : νΈν–¥μ„±; μ„¤λ…λ³€μμ μν–¥λ ¥μ΄ λ¨λ‘ μ κ±°λμ—μ„ λ• λ°μ‘λ³€μμ μƒνƒ
        - $w$ : κ°€μ¤‘μΉ; λ°μ‘λ³€μ $Y_i$ μ— λ€ν• μ„¤λ…λ³€μ $X_i$ μ μν–¥λ ¥
        - $e_i$ : μ”μ°¨ν•­; νΈν–¥μ„±κ³Ό κ°€μ¤‘μΉμ μ΅°ν•©λ§μΌλ΅λ” μ„¤λ…λ  μ μ—†λ” ν•­λ©μ λ¨μ

    - μ”μ°¨ν•­ νΉμ€ μ¤μ°¨λ” μ‹¤μ κ°’κ³Ό μμΈ΅κ°’μ μ°¨μ΄λ΅μ„ κµ¬μ²΄μ μΌλ΅ λ‹¤μμ„ μλ―Έν•¨

        ![image](https://user-images.githubusercontent.com/116495744/221339174-de431950-85c5-4156-afbc-0d3ba0b9c8e4.png)

---

## π“ μ„ ν• νκ·€(Linear Regression)

<details><summary><h3>μ„ ν• νκ·€λ€ λ¬΄μ—‡μΈκ°€</h3></summary>

- **μ •μ : μµμ†μ κ³±λ²•μ„ ν†µν•΄ νκ·€μ‹μ„ λ„μ¶ν•λ” μ•κ³ λ¦¬μ¦**

- **μµμ†μ κ³±λ²•(Ordinary Least Squares; OLS)**
    - μ •μ : μ”μ°¨ μ κ³±μ ν•©μ„ μµμ†ν™”ν•λ” νκ·€μ‹μ„ λ„μ¶ν•λ” λ°©λ²•
    - μ”μ°¨ μ κ³±μ ν•©μ„ μµμ†ν™”ν•λ‹¤λ” κ²ƒμ€ λ‹¤μμ„ μλ―Έν•¨
        
        ### $$\min\displaystyle\sum_{i=1}^ne_i^2=\min\sum_{i=1}^n(Y_i-b-wX_i)^2$$

</details>

<details><summary><h3>SK-Learnμ μ„ ν• νκ·€ μ•κ³ λ¦¬μ¦</h3></summary>
    
- **μ‚¬μ© λ°©λ²•**

    ```
    from sklearn.linear_model import LinearRegression
    from sklearn.metrics import r2_score

    # μ„ ν• νκ·€ μ•κ³ λ¦¬μ¦ μΈμ¤ν„΄μ¤ μƒμ„±
    li_reg = LinearRegression()

    # ν›λ ¨μ© λ°μ΄ν„° μ„ΈνΈλ¥Ό ν†µν•΄ μΈμ¤ν„΄μ¤λ¥Ό ν›λ ¨μ‹μΌμ„ λ¨λΈ μ„¤κ³„
    li_reg.fit(X_train, y_train)

    # ν‰κ°€μ© λ°μ΄ν„° μ„ΈνΈλ¥Ό ν†µν•΄ μμΈ΅
    y_predict = li_reg.predict(X_test)
    
    # λ€ν‘μ μΈ μ„±λ¥ ν‰κ°€ μ§€ν‘μΈ κ²°μ •κ³„μλ¥Ό ν†µν•΄ μ„±λ¥ ν‰κ°€
    score = r2_score(y_test, y_predict)
    print(score)
    ```

- **λ‹¤μμ μ†μ„±μ„ ν†µν•΄ ν›λ ¨λ λ¨λΈμ μ •λ³΄λ¥Ό ν™•μΈν•  μ μμ**
    - `n_features_in_` : μ„¤λ…λ³€μμ μ
    - `feature_nmaes_in_` : μ„¤λ…λ³€μλ…
    - `coef_` : κ° μ„¤λ…λ³€μμ κ°€μ¤‘μΉ
    - `intercept_` : νΈν–¥μ„±

- **κΈ°νƒ€ ν•μ΄νΌνλΌλ―Έν„° λ° λ¨λΈ μ •λ³΄ λ©λ΅μ€ `estimator_params`μ„ ν†µν•΄ ν™•μΈ κ°€λ¥ν•¨**

</details>

---

## π“‰ ν™•λ¥ μ  κ²½μ‚¬ ν•κ°• νκ·€(Stochastic Gradient Descent Regression; SGD)

<details><summary><h3>ν™•λ¥ μ  κ²½μ‚¬ ν•κ°• νκ·€λ€ λ¬΄μ—‡μΈκ°€</h3></summary>

- **μ •μ : κ²½μ‚¬ν•κ°•λ²•μ„ ν†µν•΄ νκ·€μ‹μ„ λ„μ¶ν•λ” μ•κ³ λ¦¬μ¦**

- **ν™•λ¥ μ  κ²½μ‚¬ν•κ°•λ²•(Stochastic Gradient Descent; SGD)**
    - **μ •μ : μµμ ν™”λ μ†μ‹¤ν•¨μμ— κ·Όκ±°ν•μ—¬ νκ·€μ‹μ„ λ„μ¶ν•λ” λ°©λ²•**
    
    - **μ†μ‹¤ν•¨μ(Loss Function)**
        - μ •μ : μ†μ‹¤μ„ λ°μ‘λ³€μ, κ°€μ¤‘μΉμ μ΅°ν•©μ„ μ„¤λ…λ³€μλ΅ κ°€μ§€λ” ν•¨μ
            - ν‰κ· μ κ³±μ¤μ°¨(MSE)μ— κΈ°μ΄ν• μ†μ‹¤ν•¨μλ” λ‹¤μμΌλ΅ μ •μλ¨

                ### $$LOSS_{MSE}=\frac{1}{N}\displaystyle\sum_{i=1}^n (\hat{Y_i}-Y_i)^2$$

        - **μ†μ‹¤(Loss)** : μ–΄λ– ν• λ°©λ²•μ— λ”°λΌ μ”μ°¨λ¥Ό κ³„μ‚°ν• κ°’

        - **μµμ ν™”(Optimizing)** : μ†μ‹¤μ„ μµμ†ν™”ν•λ” κ°€μ¤‘μΉ μ΅°ν•©μ„ μ°Ύλ” μΌ

    - **μ™ κ²½μ‚¬λ¥Ό ν•κ°•ν•λ” λ°©λ²•μ΄λΌκ³  λ¶€λ¥΄λ”κ°€?**
        - μ†μ‹¤ν•¨μμ λ°μ‘λ³€μμΈ μ†μ‹¤μ„ μµμ†ν™”ν•λ” μΌκ³„μ΅°κ±΄μ€ κ·Έ λ„ν•¨μμ λ°μ‘λ³€μκ°€ 0μ„ λ§μ΅±ν•λ” κ²ƒμ„
        - λ„ν•¨μμ λ°μ‘λ³€μλ” μ›ν•¨μμ κ²½μ‚¬(Gradient)λ¥Ό λ‚νƒ€λƒ„
        - λ”°λΌμ„ ν™•λ¥ μ  κ²½μ‚¬ν•κ°•λ²•μ€ μ›ν•¨μμ κ²½μ‚¬κ°€ μν‰μ΄ λλ” μ§€μ μ„ μ°Ύλ” μΌμ΄λΌκ³  λ³Ό μ μμ

- **μ£Όμ” μ΄μ : ν•™μµλ¥ (Learning Rate)**
    - **μ •μ : STEPμ λ‹¨μ„ νΉμ€ λ³΄ν­**
    - ν™•λ¥ μ  κ²½μ‚¬ ν•κ°• νκ·€ μ•κ³ λ¦¬μ¦μ€ λ‹¤μμ μ μ°¨λ¥Ό ν†µν•΄ κ²½μ‚¬κ°€ 0μ— κ·Όμ‚¬ν• μ§€μ μ„ μ°Ύμ
    - μ¦‰, μ„μλ΅ μ„ νƒλ μ†μ‹¤ν•¨μ κ·Έλν”„μ ν• μ μ—μ„ μ‹μ‘ν•μ—¬ ν•™μµλ¥ λ§νΌ μ›€μ§μ΄λ©΄μ„ κ²½μ‚¬λ¥Ό ν™•μΈν•¨
    - ν•™μµλ¥ μ€ μ •ν™•λ„μ— λΉ„λ΅€ν•κ³ , μ²λ¦¬ μ†λ„μ— λ°λΉ„λ΅€ν•¨

</details>

<details><summary><h3>SK-Learnμ ν™•λ¥ μ  κ²½μ‚¬ ν•κ°• νκ·€ μ•κ³ λ¦¬μ¦</h3></summary>

- **μ‚¬μ© λ°©λ²•**

    ```
    from sklearn.linear_model import SGDRegressor
    from sklearn.metrics import r2_score

    # ν™•λ¥ μ  κ²½μ‚¬ ν•κ°• νκ·€ μ•κ³ λ¦¬μ¦ μΈμ¤ν„΄μ¤ μƒμ„±
    sgd_reg = SGDRegressor()

    # ν›λ ¨μ© λ°μ΄ν„° μ„ΈνΈλ¥Ό ν†µν•΄ μΈμ¤ν„΄μ¤λ¥Ό ν›λ ¨μ‹μΌμ„ λ¨λΈ μ„¤κ³„
    sgd_reg.fit(X_train, y_train)

    # ν‰κ°€μ© λ°μ΄ν„° μ„ΈνΈλ¥Ό ν†µν•΄ μμΈ΅
    y_predict = sgd_reg.predict(X_test)
    
    # λ€ν‘μ μΈ μ„±λ¥ ν‰κ°€ μ§€ν‘μΈ κ²°μ •κ³„μλ¥Ό ν†µν•΄ μ„±λ¥ ν‰κ°€
    score = r2_score(y_test, y_predict)
    print(score)
    ```

- **μ£Όμ” ν•μ΄νΌνλΌλ―Έν„°**
    - `learning_rate = 0.1` : ν•™μµλ¥ 

- **λ‹¤μμ μ†μ„±μ„ ν†µν•΄ ν›λ ¨λ λ¨λΈμ μ •λ³΄λ¥Ό ν™•μΈν•  μ μμ**
    - `n_features_in_` : μ„¤λ…λ³€μμ μ
    - `feature_nmaes_in_` : μ„¤λ…λ³€μλ…
    - `coef_` : κ° μ„¤λ…λ³€μμ κ°€μ¤‘μΉ
    - `intercept_` : νΈν–¥μ„±

- **κΈ°νƒ€ ν•μ΄νΌνλΌλ―Έν„° λ° λ¨λΈ μ •λ³΄ λ©λ΅μ€ `estimator_params`μ„ ν†µν•΄ ν™•μΈ κ°€λ¥ν•¨**

</details>

---

## π“ Practice

- [**μ‹¤μµ μ½”λ“**]()

- [**λ°μ΄ν„° λ…μ„Έμ„**]()